{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee6dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90c65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv('training_dataset_1.csv')\n",
    "data2=pd.read_csv('training_dataset_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a7e5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/01/14 00</td>\n",
       "      <td>0.509730</td>\n",
       "      <td>2.049003</td>\n",
       "      <td>3.191145</td>\n",
       "      <td>2.792634</td>\n",
       "      <td>2.656091</td>\n",
       "      <td>5.316831</td>\n",
       "      <td>1.562321</td>\n",
       "      <td>98.998444</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.605774</td>\n",
       "      <td>26.495605</td>\n",
       "      <td>84.206619</td>\n",
       "      <td>18.901676</td>\n",
       "      <td>81.983734</td>\n",
       "      <td>18.791777</td>\n",
       "      <td>67.125603</td>\n",
       "      <td>29.387470</td>\n",
       "      <td>28.487471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06/01/14 01</td>\n",
       "      <td>0.412580</td>\n",
       "      <td>2.009072</td>\n",
       "      <td>3.642565</td>\n",
       "      <td>2.831673</td>\n",
       "      <td>3.126387</td>\n",
       "      <td>5.494855</td>\n",
       "      <td>1.852043</td>\n",
       "      <td>99.095901</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.448341</td>\n",
       "      <td>26.487326</td>\n",
       "      <td>85.900085</td>\n",
       "      <td>18.849329</td>\n",
       "      <td>82.150589</td>\n",
       "      <td>18.739643</td>\n",
       "      <td>67.178696</td>\n",
       "      <td>29.354256</td>\n",
       "      <td>28.454256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/14 02</td>\n",
       "      <td>0.320112</td>\n",
       "      <td>1.986093</td>\n",
       "      <td>4.140192</td>\n",
       "      <td>3.256733</td>\n",
       "      <td>3.574601</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.246126</td>\n",
       "      <td>98.420959</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.056114</td>\n",
       "      <td>26.487364</td>\n",
       "      <td>86.582474</td>\n",
       "      <td>19.597170</td>\n",
       "      <td>83.988579</td>\n",
       "      <td>19.496712</td>\n",
       "      <td>72.425293</td>\n",
       "      <td>29.354538</td>\n",
       "      <td>28.454538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06/01/14 03</td>\n",
       "      <td>0.332879</td>\n",
       "      <td>2.009203</td>\n",
       "      <td>4.673478</td>\n",
       "      <td>3.744497</td>\n",
       "      <td>3.952379</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.203573</td>\n",
       "      <td>97.575172</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.594353</td>\n",
       "      <td>26.575815</td>\n",
       "      <td>88.020546</td>\n",
       "      <td>26.028486</td>\n",
       "      <td>64.670486</td>\n",
       "      <td>25.922703</td>\n",
       "      <td>76.275040</td>\n",
       "      <td>29.449951</td>\n",
       "      <td>28.549952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/01/14 04</td>\n",
       "      <td>0.483496</td>\n",
       "      <td>2.089049</td>\n",
       "      <td>5.237937</td>\n",
       "      <td>4.409456</td>\n",
       "      <td>3.504676</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.439714</td>\n",
       "      <td>97.351059</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>94.473099</td>\n",
       "      <td>26.723457</td>\n",
       "      <td>90.422462</td>\n",
       "      <td>26.209970</td>\n",
       "      <td>64.746620</td>\n",
       "      <td>26.104692</td>\n",
       "      <td>76.703529</td>\n",
       "      <td>29.574265</td>\n",
       "      <td>28.674263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATETIME      L_T1      L_T2      L_T3      L_T4      L_T5      L_T6  \\\n",
       "0  06/01/14 00  0.509730  2.049003  3.191145  2.792634  2.656091  5.316831   \n",
       "1  06/01/14 01  0.412580  2.009072  3.642565  2.831673  3.126387  5.494855   \n",
       "2  06/01/14 02  0.320112  1.986093  4.140192  3.256733  3.574601  5.500000   \n",
       "3  06/01/14 03  0.332879  2.009203  4.673478  3.744497  3.952379  5.500000   \n",
       "4  06/01/14 04  0.483496  2.089049  5.237937  4.409456  3.504676  5.500000   \n",
       "\n",
       "       L_T7      F_PU1  S_PU1  ...     P_J256     P_J289     P_J415  \\\n",
       "0  1.562321  98.998444      1  ...  87.605774  26.495605  84.206619   \n",
       "1  1.852043  99.095901      1  ...  89.448341  26.487326  85.900085   \n",
       "2  2.246126  98.420959      1  ...  91.056114  26.487364  86.582474   \n",
       "3  3.203573  97.575172      1  ...  92.594353  26.575815  88.020546   \n",
       "4  4.439714  97.351059      1  ...  94.473099  26.723457  90.422462   \n",
       "\n",
       "      P_J302     P_J306     P_J307     P_J317      P_J14     P_J422  ATT_FLAG  \n",
       "0  18.901676  81.983734  18.791777  67.125603  29.387470  28.487471         0  \n",
       "1  18.849329  82.150589  18.739643  67.178696  29.354256  28.454256         0  \n",
       "2  19.597170  83.988579  19.496712  72.425293  29.354538  28.454538         0  \n",
       "3  26.028486  64.670486  25.922703  76.275040  29.449951  28.549952         0  \n",
       "4  26.209970  64.746620  26.104692  76.703529  29.574265  28.674263         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a11ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/07/16 00</td>\n",
       "      <td>2.44</td>\n",
       "      <td>5.24</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.86</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.39</td>\n",
       "      <td>93.63</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>70.00</td>\n",
       "      <td>28.22</td>\n",
       "      <td>85.87</td>\n",
       "      <td>21.69</td>\n",
       "      <td>82.72</td>\n",
       "      <td>21.58</td>\n",
       "      <td>71.99</td>\n",
       "      <td>39.33</td>\n",
       "      <td>29.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/07/16 01</td>\n",
       "      <td>2.66</td>\n",
       "      <td>4.53</td>\n",
       "      <td>3.20</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.29</td>\n",
       "      <td>5.44</td>\n",
       "      <td>4.53</td>\n",
       "      <td>89.41</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.73</td>\n",
       "      <td>24.45</td>\n",
       "      <td>84.87</td>\n",
       "      <td>29.81</td>\n",
       "      <td>86.62</td>\n",
       "      <td>29.81</td>\n",
       "      <td>59.76</td>\n",
       "      <td>42.17</td>\n",
       "      <td>26.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/07/16 02</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.87</td>\n",
       "      <td>5.15</td>\n",
       "      <td>3.22</td>\n",
       "      <td>89.88</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.29</td>\n",
       "      <td>23.90</td>\n",
       "      <td>87.11</td>\n",
       "      <td>29.85</td>\n",
       "      <td>87.64</td>\n",
       "      <td>29.85</td>\n",
       "      <td>58.50</td>\n",
       "      <td>42.00</td>\n",
       "      <td>25.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/07/16 03</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.04</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.98</td>\n",
       "      <td>2.40</td>\n",
       "      <td>88.10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.98</td>\n",
       "      <td>27.10</td>\n",
       "      <td>68.75</td>\n",
       "      <td>31.60</td>\n",
       "      <td>64.25</td>\n",
       "      <td>31.47</td>\n",
       "      <td>72.30</td>\n",
       "      <td>43.24</td>\n",
       "      <td>28.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/07/16 04</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.68</td>\n",
       "      <td>4.73</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3.11</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3.46</td>\n",
       "      <td>87.01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.11</td>\n",
       "      <td>26.76</td>\n",
       "      <td>68.74</td>\n",
       "      <td>32.30</td>\n",
       "      <td>64.23</td>\n",
       "      <td>32.17</td>\n",
       "      <td>72.53</td>\n",
       "      <td>44.00</td>\n",
       "      <td>28.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATETIME  L_T1  L_T2  L_T3  L_T4  L_T5  L_T6  L_T7  F_PU1  S_PU1  ...  \\\n",
       "0  04/07/16 00  2.44  5.24  3.19  4.10  2.86  5.50  4.39  93.63      1  ...   \n",
       "1  04/07/16 01  2.66  4.53  3.20  4.18  3.29  5.44  4.53  89.41      1  ...   \n",
       "2  04/07/16 02  3.11  3.66  3.66  4.21  3.87  5.15  3.22  89.88      1  ...   \n",
       "3  04/07/16 03  3.62  3.04  4.17  4.04  3.56  4.98  2.40  88.10      1  ...   \n",
       "4  04/07/16 04  4.08  2.68  4.73  3.20  3.11  5.39  3.46  87.01      1  ...   \n",
       "\n",
       "   P_J256  P_J289  P_J415  P_J302  P_J306  P_J307  P_J317  P_J14  P_J422  \\\n",
       "0   70.00   28.22   85.87   21.69   82.72   21.58   71.99  39.33   29.64   \n",
       "1   87.73   24.45   84.87   29.81   86.62   29.81   59.76  42.17   26.15   \n",
       "2   89.29   23.90   87.11   29.85   87.64   29.85   58.50  42.00   25.56   \n",
       "3   91.98   27.10   68.75   31.60   64.25   31.47   72.30  43.24   28.38   \n",
       "4   92.11   26.76   68.74   32.30   64.23   32.17   72.53  44.00   28.04   \n",
       "\n",
       "   ATT_FLAG  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac00609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8761, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f313afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4177, 45)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2732a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8761 entries, 0 to 8760\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DATETIME  8761 non-null   object \n",
      " 1   L_T1      8761 non-null   float64\n",
      " 2   L_T2      8761 non-null   float64\n",
      " 3   L_T3      8761 non-null   float64\n",
      " 4   L_T4      8761 non-null   float64\n",
      " 5   L_T5      8761 non-null   float64\n",
      " 6   L_T6      8761 non-null   float64\n",
      " 7   L_T7      8761 non-null   float64\n",
      " 8   F_PU1     8761 non-null   float64\n",
      " 9   S_PU1     8761 non-null   int64  \n",
      " 10  F_PU2     8761 non-null   float64\n",
      " 11  S_PU2     8761 non-null   int64  \n",
      " 12  F_PU3     8761 non-null   int64  \n",
      " 13  S_PU3     8761 non-null   int64  \n",
      " 14  F_PU4     8761 non-null   float64\n",
      " 15  S_PU4     8761 non-null   int64  \n",
      " 16  F_PU5     8761 non-null   int64  \n",
      " 17  S_PU5     8761 non-null   int64  \n",
      " 18  F_PU6     8761 non-null   float64\n",
      " 19  S_PU6     8761 non-null   int64  \n",
      " 20  F_PU7     8761 non-null   float64\n",
      " 21  S_PU7     8761 non-null   int64  \n",
      " 22  F_PU8     8761 non-null   float64\n",
      " 23  S_PU8     8761 non-null   int64  \n",
      " 24  F_PU9     8761 non-null   int64  \n",
      " 25  S_PU9     8761 non-null   int64  \n",
      " 26  F_PU10    8761 non-null   float64\n",
      " 27  S_PU10    8761 non-null   int64  \n",
      " 28  F_PU11    8761 non-null   float64\n",
      " 29  S_PU11    8761 non-null   int64  \n",
      " 30  F_V2      8761 non-null   float64\n",
      " 31  S_V2      8761 non-null   int64  \n",
      " 32  P_J280    8761 non-null   float64\n",
      " 33  P_J269    8761 non-null   float64\n",
      " 34  P_J300    8761 non-null   float64\n",
      " 35  P_J256    8761 non-null   float64\n",
      " 36  P_J289    8761 non-null   float64\n",
      " 37  P_J415    8761 non-null   float64\n",
      " 38  P_J302    8761 non-null   float64\n",
      " 39  P_J306    8761 non-null   float64\n",
      " 40  P_J307    8761 non-null   float64\n",
      " 41  P_J317    8761 non-null   float64\n",
      " 42  P_J14     8761 non-null   float64\n",
      " 43  P_J422    8761 non-null   float64\n",
      " 44  ATT_FLAG  8761 non-null   int64  \n",
      "dtypes: float64(28), int64(16), object(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50dc1933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DATETIME  4177 non-null   object \n",
      " 1   L_T1      4177 non-null   float64\n",
      " 2   L_T2      4177 non-null   float64\n",
      " 3   L_T3      4177 non-null   float64\n",
      " 4   L_T4      4177 non-null   float64\n",
      " 5   L_T5      4177 non-null   float64\n",
      " 6   L_T6      4177 non-null   float64\n",
      " 7   L_T7      4177 non-null   float64\n",
      " 8   F_PU1     4177 non-null   float64\n",
      " 9   S_PU1     4177 non-null   int64  \n",
      " 10  F_PU2     4177 non-null   float64\n",
      " 11  S_PU2     4177 non-null   int64  \n",
      " 12  F_PU3     4177 non-null   int64  \n",
      " 13  S_PU3     4177 non-null   int64  \n",
      " 14  F_PU4     4177 non-null   float64\n",
      " 15  S_PU4     4177 non-null   int64  \n",
      " 16  F_PU5     4177 non-null   int64  \n",
      " 17  S_PU5     4177 non-null   int64  \n",
      " 18  F_PU6     4177 non-null   float64\n",
      " 19  S_PU6     4177 non-null   int64  \n",
      " 20  F_PU7     4177 non-null   float64\n",
      " 21  S_PU7     4177 non-null   int64  \n",
      " 22  F_PU8     4177 non-null   float64\n",
      " 23  S_PU8     4177 non-null   int64  \n",
      " 24  F_PU9     4177 non-null   int64  \n",
      " 25  S_PU9     4177 non-null   int64  \n",
      " 26  F_PU10    4177 non-null   float64\n",
      " 27  S_PU10    4177 non-null   int64  \n",
      " 28  F_PU11    4177 non-null   float64\n",
      " 29  S_PU11    4177 non-null   int64  \n",
      " 30  F_V2      4177 non-null   float64\n",
      " 31  S_V2      4177 non-null   int64  \n",
      " 32  P_J280    4177 non-null   float64\n",
      " 33  P_J269    4177 non-null   float64\n",
      " 34  P_J300    4177 non-null   float64\n",
      " 35  P_J256    4177 non-null   float64\n",
      " 36  P_J289    4177 non-null   float64\n",
      " 37  P_J415    4177 non-null   float64\n",
      " 38  P_J302    4177 non-null   float64\n",
      " 39  P_J306    4177 non-null   float64\n",
      " 40  P_J307    4177 non-null   float64\n",
      " 41  P_J317    4177 non-null   float64\n",
      " 42  P_J14     4177 non-null   float64\n",
      " 43  P_J422    4177 non-null   float64\n",
      " 44  ATT_FLAG  4177 non-null   int64  \n",
      "dtypes: float64(28), int64(16), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72dfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data1,data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dadea1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32447e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>L_T1</th>\n",
       "      <th>L_T2</th>\n",
       "      <th>L_T3</th>\n",
       "      <th>L_T4</th>\n",
       "      <th>L_T5</th>\n",
       "      <th>L_T6</th>\n",
       "      <th>L_T7</th>\n",
       "      <th>F_PU1</th>\n",
       "      <th>S_PU1</th>\n",
       "      <th>...</th>\n",
       "      <th>P_J256</th>\n",
       "      <th>P_J289</th>\n",
       "      <th>P_J415</th>\n",
       "      <th>P_J302</th>\n",
       "      <th>P_J306</th>\n",
       "      <th>P_J307</th>\n",
       "      <th>P_J317</th>\n",
       "      <th>P_J14</th>\n",
       "      <th>P_J422</th>\n",
       "      <th>ATT_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/01/14 00</td>\n",
       "      <td>0.509730</td>\n",
       "      <td>2.049003</td>\n",
       "      <td>3.191145</td>\n",
       "      <td>2.792634</td>\n",
       "      <td>2.656091</td>\n",
       "      <td>5.316831</td>\n",
       "      <td>1.562321</td>\n",
       "      <td>98.998444</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87.605774</td>\n",
       "      <td>26.495605</td>\n",
       "      <td>84.206619</td>\n",
       "      <td>18.901676</td>\n",
       "      <td>81.983734</td>\n",
       "      <td>18.791777</td>\n",
       "      <td>67.125603</td>\n",
       "      <td>29.387470</td>\n",
       "      <td>28.487471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06/01/14 01</td>\n",
       "      <td>0.412580</td>\n",
       "      <td>2.009072</td>\n",
       "      <td>3.642565</td>\n",
       "      <td>2.831673</td>\n",
       "      <td>3.126387</td>\n",
       "      <td>5.494855</td>\n",
       "      <td>1.852043</td>\n",
       "      <td>99.095901</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>89.448341</td>\n",
       "      <td>26.487326</td>\n",
       "      <td>85.900085</td>\n",
       "      <td>18.849329</td>\n",
       "      <td>82.150589</td>\n",
       "      <td>18.739643</td>\n",
       "      <td>67.178696</td>\n",
       "      <td>29.354256</td>\n",
       "      <td>28.454256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/14 02</td>\n",
       "      <td>0.320112</td>\n",
       "      <td>1.986093</td>\n",
       "      <td>4.140192</td>\n",
       "      <td>3.256733</td>\n",
       "      <td>3.574601</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.246126</td>\n",
       "      <td>98.420959</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>91.056114</td>\n",
       "      <td>26.487364</td>\n",
       "      <td>86.582474</td>\n",
       "      <td>19.597170</td>\n",
       "      <td>83.988579</td>\n",
       "      <td>19.496712</td>\n",
       "      <td>72.425293</td>\n",
       "      <td>29.354538</td>\n",
       "      <td>28.454538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06/01/14 03</td>\n",
       "      <td>0.332879</td>\n",
       "      <td>2.009203</td>\n",
       "      <td>4.673478</td>\n",
       "      <td>3.744497</td>\n",
       "      <td>3.952379</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3.203573</td>\n",
       "      <td>97.575172</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>92.594353</td>\n",
       "      <td>26.575815</td>\n",
       "      <td>88.020546</td>\n",
       "      <td>26.028486</td>\n",
       "      <td>64.670486</td>\n",
       "      <td>25.922703</td>\n",
       "      <td>76.275040</td>\n",
       "      <td>29.449951</td>\n",
       "      <td>28.549952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06/01/14 04</td>\n",
       "      <td>0.483496</td>\n",
       "      <td>2.089049</td>\n",
       "      <td>5.237937</td>\n",
       "      <td>4.409456</td>\n",
       "      <td>3.504676</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.439714</td>\n",
       "      <td>97.351059</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>94.473099</td>\n",
       "      <td>26.723457</td>\n",
       "      <td>90.422462</td>\n",
       "      <td>26.209970</td>\n",
       "      <td>64.746620</td>\n",
       "      <td>26.104692</td>\n",
       "      <td>76.703529</td>\n",
       "      <td>29.574265</td>\n",
       "      <td>28.674263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATETIME      L_T1      L_T2      L_T3      L_T4      L_T5      L_T6  \\\n",
       "0  06/01/14 00  0.509730  2.049003  3.191145  2.792634  2.656091  5.316831   \n",
       "1  06/01/14 01  0.412580  2.009072  3.642565  2.831673  3.126387  5.494855   \n",
       "2  06/01/14 02  0.320112  1.986093  4.140192  3.256733  3.574601  5.500000   \n",
       "3  06/01/14 03  0.332879  2.009203  4.673478  3.744497  3.952379  5.500000   \n",
       "4  06/01/14 04  0.483496  2.089049  5.237937  4.409456  3.504676  5.500000   \n",
       "\n",
       "       L_T7      F_PU1  S_PU1  ...     P_J256     P_J289     P_J415  \\\n",
       "0  1.562321  98.998444      1  ...  87.605774  26.495605  84.206619   \n",
       "1  1.852043  99.095901      1  ...  89.448341  26.487326  85.900085   \n",
       "2  2.246126  98.420959      1  ...  91.056114  26.487364  86.582474   \n",
       "3  3.203573  97.575172      1  ...  92.594353  26.575815  88.020546   \n",
       "4  4.439714  97.351059      1  ...  94.473099  26.723457  90.422462   \n",
       "\n",
       "      P_J302     P_J306     P_J307     P_J317      P_J14     P_J422  ATT_FLAG  \n",
       "0  18.901676  81.983734  18.791777  67.125603  29.387470  28.487471         0  \n",
       "1  18.849329  82.150589  18.739643  67.178696  29.354256  28.454256         0  \n",
       "2  19.597170  83.988579  19.496712  72.425293  29.354538  28.454538         0  \n",
       "3  26.028486  64.670486  25.922703  76.275040  29.449951  28.549952         0  \n",
       "4  26.209970  64.746620  26.104692  76.703529  29.574265  28.674263         0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1bd734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12938, 45)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7e05e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12938 entries, 0 to 4176\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DATETIME  12938 non-null  object \n",
      " 1   L_T1      12938 non-null  float64\n",
      " 2   L_T2      12938 non-null  float64\n",
      " 3   L_T3      12938 non-null  float64\n",
      " 4   L_T4      12938 non-null  float64\n",
      " 5   L_T5      12938 non-null  float64\n",
      " 6   L_T6      12938 non-null  float64\n",
      " 7   L_T7      12938 non-null  float64\n",
      " 8   F_PU1     12938 non-null  float64\n",
      " 9   S_PU1     12938 non-null  int64  \n",
      " 10  F_PU2     12938 non-null  float64\n",
      " 11  S_PU2     12938 non-null  int64  \n",
      " 12  F_PU3     12938 non-null  int64  \n",
      " 13  S_PU3     12938 non-null  int64  \n",
      " 14  F_PU4     12938 non-null  float64\n",
      " 15  S_PU4     12938 non-null  int64  \n",
      " 16  F_PU5     12938 non-null  int64  \n",
      " 17  S_PU5     12938 non-null  int64  \n",
      " 18  F_PU6     12938 non-null  float64\n",
      " 19  S_PU6     12938 non-null  int64  \n",
      " 20  F_PU7     12938 non-null  float64\n",
      " 21  S_PU7     12938 non-null  int64  \n",
      " 22  F_PU8     12938 non-null  float64\n",
      " 23  S_PU8     12938 non-null  int64  \n",
      " 24  F_PU9     12938 non-null  int64  \n",
      " 25  S_PU9     12938 non-null  int64  \n",
      " 26  F_PU10    12938 non-null  float64\n",
      " 27  S_PU10    12938 non-null  int64  \n",
      " 28  F_PU11    12938 non-null  float64\n",
      " 29  S_PU11    12938 non-null  int64  \n",
      " 30  F_V2      12938 non-null  float64\n",
      " 31  S_V2      12938 non-null  int64  \n",
      " 32  P_J280    12938 non-null  float64\n",
      " 33  P_J269    12938 non-null  float64\n",
      " 34  P_J300    12938 non-null  float64\n",
      " 35  P_J256    12938 non-null  float64\n",
      " 36  P_J289    12938 non-null  float64\n",
      " 37  P_J415    12938 non-null  float64\n",
      " 38  P_J302    12938 non-null  float64\n",
      " 39  P_J306    12938 non-null  float64\n",
      " 40  P_J307    12938 non-null  float64\n",
      " 41  P_J317    12938 non-null  float64\n",
      " 42  P_J14     12938 non-null  float64\n",
      " 43  P_J422    12938 non-null  float64\n",
      " 44  ATT_FLAG  12938 non-null  int64  \n",
      "dtypes: float64(28), int64(16), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "full_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff9d1cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='ATT_FLAG', ylabel='count'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=full_df,x='ATT_FLAG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc14f746",
   "metadata": {},
   "source": [
    "# Handle Imbalance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd7613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9533137",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_df.drop(['DATETIME','ATT_FLAG'],axis=1)\n",
    "y = full_df['ATT_FLAG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b6afc5",
   "metadata": {},
   "source": [
    "# Spliting the data Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7049fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516f9f8",
   "metadata": {},
   "source": [
    "## 1. Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "690afe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os=RandomOverSampler(sampling_strategy='minority')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cbe534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_os,y_train_os=os.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bca51e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 9961, 1: 389})\n",
      "The number of classes after fit Counter({0: 9961, 1: 9961})\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_os)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e4a71",
   "metadata": {},
   "source": [
    "## 2. SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7883cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_tet=SMOTETomek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05581fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smtet,y_train_smtet=sm_tet.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc112340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 9961, 1: 389})\n",
      "The number of classes after fit Counter({0: 9958, 1: 9958})\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_smtet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2ba04",
   "metadata": {},
   "source": [
    "## 3. SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55943549",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e51f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smo,y_train_smo=smote.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8faa30da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 9961, 1: 389})\n",
      "The number of classes after fit Counter({0: 9958, 1: 9958})\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_smtet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb8a1a",
   "metadata": {},
   "source": [
    "# Scaling of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11efe882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7610c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "min_max = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96accd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_os=min_max.fit_transform(X_train_os)\n",
    "X_train_smtet=min_max.fit_transform(X_train_smtet)\n",
    "X_train_smo=min_max.fit_transform(X_train_smo)\n",
    "X_test=min_max.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f212b41",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aef5cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bab080fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classalgo_test(x_train,x_test,y_train,y_test): #classification\n",
    "      \n",
    "    g=GaussianNB()\n",
    "    b=BernoulliNB()\n",
    "    kc=KNeighborsClassifier()\n",
    "    lr=LogisticRegression()\n",
    "    dc=DecisionTreeClassifier()\n",
    "    rfc=RandomForestClassifier()\n",
    "    gbc=GradientBoostingClassifier()\n",
    "    xgb=XGBClassifier()\n",
    "    Bagging=BaggingClassifier()\n",
    "    AdaBoost=AdaBoostClassifier()\n",
    "    \n",
    "    algos = [g,b,kc,lr,dc,rfc,gbc,xgb,Bagging,AdaBoost]\n",
    "    algo_names = ['GaussianNB','BernoulliNB','KNeighborsClassifier','LogisticRegression','DecisionTreeClassifier','RandomForestClassifier','GradientBoostingClassifier','BaggingClassifier','XGBClassifier','AdaBoostClassifier']\n",
    "    Train_acc=[]\n",
    "    Train_precsc=[]\n",
    "    Train_fsc=[]\n",
    "    Train_Recall=[]\n",
    "    Test_acc=[]\n",
    "    Test_precsc=[]\n",
    "    Test_fsc=[]\n",
    "    Test_Recall=[]\n",
    "    Test_AUC=[]\n",
    "    \n",
    "    result = pd.DataFrame(index = algo_names)\n",
    "    \n",
    "    for algo in algos:\n",
    "    \n",
    "        algo.fit(x_train,y_train)\n",
    "        y_train_pred = algo.predict(x_train)\n",
    "        y_test_pred = algo.predict(x_test)\n",
    "        Train_acc.append(accuracy_score(y_train,y_train_pred))\n",
    "        Train_precsc.append(precision_score(y_train,y_train_pred))\n",
    "        Train_fsc.append(f1_score(y_train,y_train_pred))\n",
    "        Train_Recall.append(recall_score(y_train,y_train_pred,average='micro'))\n",
    "        \n",
    "        \n",
    "        Test_acc.append(accuracy_score(y_test,y_test_pred))\n",
    "        Test_precsc.append(precision_score(y_test,y_test_pred))\n",
    "        Test_fsc.append(f1_score(y_test,y_test_pred))\n",
    "        Test_Recall.append(recall_score(y_test,y_test_pred,average='micro'))\n",
    "        Test_AUC.append(roc_auc_score(y_test,y_test_pred))\n",
    "        \n",
    "    \n",
    "    result['Train_Accuracy Score'] = Train_acc\n",
    "    result['Train_Precision Score'] = Train_precsc\n",
    "    result['Train_F1Score']= Train_fsc\n",
    "    result['Train_Recall']= Train_Recall    \n",
    "    result['Test_Accuracy Score'] = Test_acc\n",
    "    result['Test_Precision Score'] = Test_precsc\n",
    "    result['Test_F1Score']= Test_fsc\n",
    "    result['Test_Recall']= Test_Recall\n",
    "    result['Test_AUC_Score']= Test_AUC\n",
    "        \n",
    "    return result.sort_values('Test_Accuracy Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e76027a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy Score</th>\n",
       "      <th>Train_Precision Score</th>\n",
       "      <th>Train_F1Score</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Accuracy Score</th>\n",
       "      <th>Test_Precision Score</th>\n",
       "      <th>Test_F1Score</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_AUC_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978362</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.670588</td>\n",
       "      <td>0.978362</td>\n",
       "      <td>0.774687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976430</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.976430</td>\n",
       "      <td>0.722496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.615601</td>\n",
       "      <td>0.990626</td>\n",
       "      <td>0.377803</td>\n",
       "      <td>0.615601</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>0.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.969861</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.969861</td>\n",
       "      <td>0.705116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963679</td>\n",
       "      <td>0.554217</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.963679</td>\n",
       "      <td>0.715856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.990413</td>\n",
       "      <td>0.981186</td>\n",
       "      <td>0.990504</td>\n",
       "      <td>0.990413</td>\n",
       "      <td>0.955564</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.502165</td>\n",
       "      <td>0.955564</td>\n",
       "      <td>0.767469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.950306</td>\n",
       "      <td>0.915748</td>\n",
       "      <td>0.952289</td>\n",
       "      <td>0.950306</td>\n",
       "      <td>0.903787</td>\n",
       "      <td>0.274691</td>\n",
       "      <td>0.416862</td>\n",
       "      <td>0.903787</td>\n",
       "      <td>0.884755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.642456</td>\n",
       "      <td>0.774256</td>\n",
       "      <td>0.529369</td>\n",
       "      <td>0.642456</td>\n",
       "      <td>0.870943</td>\n",
       "      <td>0.140187</td>\n",
       "      <td>0.212264</td>\n",
       "      <td>0.870943</td>\n",
       "      <td>0.662913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.910652</td>\n",
       "      <td>0.882540</td>\n",
       "      <td>0.913818</td>\n",
       "      <td>0.910652</td>\n",
       "      <td>0.867852</td>\n",
       "      <td>0.206388</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.867852</td>\n",
       "      <td>0.842777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.771158</td>\n",
       "      <td>0.828030</td>\n",
       "      <td>0.749437</td>\n",
       "      <td>0.771158</td>\n",
       "      <td>0.846213</td>\n",
       "      <td>0.159353</td>\n",
       "      <td>0.257463</td>\n",
       "      <td>0.846213</td>\n",
       "      <td>0.761712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train_Accuracy Score  Train_Precision Score  \\\n",
       "BaggingClassifier                       1.000000               1.000000   \n",
       "RandomForestClassifier                  1.000000               1.000000   \n",
       "GaussianNB                              0.615601               0.990626   \n",
       "XGBClassifier                           0.999950               0.999900   \n",
       "DecisionTreeClassifier                  1.000000               1.000000   \n",
       "KNeighborsClassifier                    0.990413               0.981186   \n",
       "GradientBoostingClassifier              0.950306               0.915748   \n",
       "BernoulliNB                             0.642456               0.774256   \n",
       "AdaBoostClassifier                      0.910652               0.882540   \n",
       "LogisticRegression                      0.771158               0.828030   \n",
       "\n",
       "                            Train_F1Score  Train_Recall  Test_Accuracy Score  \\\n",
       "BaggingClassifier                1.000000      1.000000             0.978362   \n",
       "RandomForestClassifier           1.000000      1.000000             0.976430   \n",
       "GaussianNB                       0.377803      0.615601             0.970634   \n",
       "XGBClassifier                    0.999950      0.999950             0.969861   \n",
       "DecisionTreeClassifier           1.000000      1.000000             0.963679   \n",
       "KNeighborsClassifier             0.990504      0.990413             0.955564   \n",
       "GradientBoostingClassifier       0.952289      0.950306             0.903787   \n",
       "BernoulliNB                      0.529369      0.642456             0.870943   \n",
       "AdaBoostClassifier               0.913818      0.910652             0.867852   \n",
       "LogisticRegression               0.749437      0.771158             0.846213   \n",
       "\n",
       "                            Test_Precision Score  Test_F1Score  Test_Recall  \\\n",
       "BaggingClassifier                       0.850746      0.670588     0.978362   \n",
       "RandomForestClassifier                  0.920000      0.601307     0.976430   \n",
       "GaussianNB                              0.864865      0.457143     0.970634   \n",
       "XGBClassifier                           0.704918      0.524390     0.969861   \n",
       "DecisionTreeClassifier                  0.554217      0.494624     0.963679   \n",
       "KNeighborsClassifier                    0.453125      0.502165     0.955564   \n",
       "GradientBoostingClassifier              0.274691      0.416862     0.903787   \n",
       "BernoulliNB                             0.140187      0.212264     0.870943   \n",
       "AdaBoostClassifier                      0.206388      0.329412     0.867852   \n",
       "LogisticRegression                      0.159353      0.257463     0.846213   \n",
       "\n",
       "                            Test_AUC_Score  \n",
       "BaggingClassifier                 0.774687  \n",
       "RandomForestClassifier            0.722496  \n",
       "GaussianNB                        0.654334  \n",
       "XGBClassifier                     0.705116  \n",
       "DecisionTreeClassifier            0.715856  \n",
       "KNeighborsClassifier              0.767469  \n",
       "GradientBoostingClassifier        0.884755  \n",
       "BernoulliNB                       0.662913  \n",
       "AdaBoostClassifier                0.842777  \n",
       "LogisticRegression                0.761712  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classalgo_test(X_train_os,X_test,y_train_os,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ff72642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy Score</th>\n",
       "      <th>Train_Precision Score</th>\n",
       "      <th>Train_F1Score</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Accuracy Score</th>\n",
       "      <th>Test_Precision Score</th>\n",
       "      <th>Test_F1Score</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_AUC_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975270</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.975270</td>\n",
       "      <td>0.800996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.614380</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>0.374593</td>\n",
       "      <td>0.614380</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>0.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.970247</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.970247</td>\n",
       "      <td>0.803034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.998996</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.999046</td>\n",
       "      <td>0.961360</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.514563</td>\n",
       "      <td>0.961360</td>\n",
       "      <td>0.747221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947450</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.947450</td>\n",
       "      <td>0.749284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.976200</td>\n",
       "      <td>0.955349</td>\n",
       "      <td>0.976733</td>\n",
       "      <td>0.976200</td>\n",
       "      <td>0.925425</td>\n",
       "      <td>0.299107</td>\n",
       "      <td>0.409786</td>\n",
       "      <td>0.925425</td>\n",
       "      <td>0.793653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.922474</td>\n",
       "      <td>0.903665</td>\n",
       "      <td>0.924239</td>\n",
       "      <td>0.922474</td>\n",
       "      <td>0.889490</td>\n",
       "      <td>0.230088</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.889490</td>\n",
       "      <td>0.826126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.890239</td>\n",
       "      <td>0.881654</td>\n",
       "      <td>0.891460</td>\n",
       "      <td>0.890239</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>0.195822</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>0.870170</td>\n",
       "      <td>0.802106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.778369</td>\n",
       "      <td>0.835187</td>\n",
       "      <td>0.757845</td>\n",
       "      <td>0.778369</td>\n",
       "      <td>0.856260</td>\n",
       "      <td>0.172749</td>\n",
       "      <td>0.276265</td>\n",
       "      <td>0.856260</td>\n",
       "      <td>0.776250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.623720</td>\n",
       "      <td>0.725641</td>\n",
       "      <td>0.513945</td>\n",
       "      <td>0.623720</td>\n",
       "      <td>0.840031</td>\n",
       "      <td>0.123487</td>\n",
       "      <td>0.197674</td>\n",
       "      <td>0.840031</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train_Accuracy Score  Train_Precision Score  \\\n",
       "RandomForestClassifier                  1.000000               1.000000   \n",
       "GaussianNB                              0.614380               0.990525   \n",
       "BaggingClassifier                       0.999799               0.999900   \n",
       "XGBClassifier                           0.999046               0.998996   \n",
       "DecisionTreeClassifier                  1.000000               1.000000   \n",
       "KNeighborsClassifier                    0.976200               0.955349   \n",
       "GradientBoostingClassifier              0.922474               0.903665   \n",
       "AdaBoostClassifier                      0.890239               0.881654   \n",
       "LogisticRegression                      0.778369               0.835187   \n",
       "BernoulliNB                             0.623720               0.725641   \n",
       "\n",
       "                            Train_F1Score  Train_Recall  Test_Accuracy Score  \\\n",
       "RandomForestClassifier           1.000000      1.000000             0.975270   \n",
       "GaussianNB                       0.374593      0.614380             0.970634   \n",
       "BaggingClassifier                0.999799      0.999799             0.970247   \n",
       "XGBClassifier                    0.999046      0.999046             0.961360   \n",
       "DecisionTreeClassifier           1.000000      1.000000             0.947450   \n",
       "KNeighborsClassifier             0.976733      0.976200             0.925425   \n",
       "GradientBoostingClassifier       0.924239      0.922474             0.889490   \n",
       "AdaBoostClassifier               0.891460      0.890239             0.870170   \n",
       "LogisticRegression               0.757845      0.778369             0.856260   \n",
       "BernoulliNB                      0.513945      0.623720             0.840031   \n",
       "\n",
       "                            Test_Precision Score  Test_F1Score  Test_Recall  \\\n",
       "RandomForestClassifier                  0.724138      0.663158     0.975270   \n",
       "GaussianNB                              0.864865      0.457143     0.970634   \n",
       "BaggingClassifier                       0.627451      0.624390     0.970247   \n",
       "XGBClassifier                           0.514563      0.514563     0.961360   \n",
       "DecisionTreeClassifier                  0.384615      0.447154     0.947450   \n",
       "KNeighborsClassifier                    0.299107      0.409786     0.925425   \n",
       "GradientBoostingClassifier              0.230088      0.352941     0.889490   \n",
       "AdaBoostClassifier                      0.195822      0.308642     0.870170   \n",
       "LogisticRegression                      0.172749      0.276265     0.856260   \n",
       "BernoulliNB                             0.123487      0.197674     0.840031   \n",
       "\n",
       "                            Test_AUC_Score  \n",
       "RandomForestClassifier            0.800996  \n",
       "GaussianNB                        0.654334  \n",
       "BaggingClassifier                 0.803034  \n",
       "XGBClassifier                     0.747221  \n",
       "DecisionTreeClassifier            0.749284  \n",
       "KNeighborsClassifier              0.793653  \n",
       "GradientBoostingClassifier        0.826126  \n",
       "AdaBoostClassifier                0.802106  \n",
       "LogisticRegression                0.776250  \n",
       "BernoulliNB                       0.674736  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classalgo_test(X_train_smtet,X_test,y_train_smtet,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27e8a513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train_Accuracy Score</th>\n",
       "      <th>Train_Precision Score</th>\n",
       "      <th>Train_F1Score</th>\n",
       "      <th>Train_Recall</th>\n",
       "      <th>Test_Accuracy Score</th>\n",
       "      <th>Test_Precision Score</th>\n",
       "      <th>Test_F1Score</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_AUC_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972566</td>\n",
       "      <td>0.686047</td>\n",
       "      <td>0.624339</td>\n",
       "      <td>0.972566</td>\n",
       "      <td>0.780975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.971793</td>\n",
       "      <td>0.803839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.612439</td>\n",
       "      <td>0.990368</td>\n",
       "      <td>0.369457</td>\n",
       "      <td>0.612439</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.970634</td>\n",
       "      <td>0.654334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.999147</td>\n",
       "      <td>0.999397</td>\n",
       "      <td>0.999146</td>\n",
       "      <td>0.999147</td>\n",
       "      <td>0.962519</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.531401</td>\n",
       "      <td>0.962519</td>\n",
       "      <td>0.757131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947836</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.453441</td>\n",
       "      <td>0.947836</td>\n",
       "      <td>0.754138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.974802</td>\n",
       "      <td>0.952800</td>\n",
       "      <td>0.975399</td>\n",
       "      <td>0.974802</td>\n",
       "      <td>0.926584</td>\n",
       "      <td>0.308370</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.926584</td>\n",
       "      <td>0.808216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.921946</td>\n",
       "      <td>0.898464</td>\n",
       "      <td>0.924180</td>\n",
       "      <td>0.921946</td>\n",
       "      <td>0.881762</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.881762</td>\n",
       "      <td>0.836061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.888565</td>\n",
       "      <td>0.873709</td>\n",
       "      <td>0.890737</td>\n",
       "      <td>0.888565</td>\n",
       "      <td>0.868238</td>\n",
       "      <td>0.199495</td>\n",
       "      <td>0.316633</td>\n",
       "      <td>0.868238</td>\n",
       "      <td>0.819712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.780544</td>\n",
       "      <td>0.833194</td>\n",
       "      <td>0.761718</td>\n",
       "      <td>0.780544</td>\n",
       "      <td>0.853168</td>\n",
       "      <td>0.171021</td>\n",
       "      <td>0.274809</td>\n",
       "      <td>0.853168</td>\n",
       "      <td>0.779293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.615099</td>\n",
       "      <td>0.697163</td>\n",
       "      <td>0.513945</td>\n",
       "      <td>0.615099</td>\n",
       "      <td>0.809119</td>\n",
       "      <td>0.101833</td>\n",
       "      <td>0.168350</td>\n",
       "      <td>0.809119</td>\n",
       "      <td>0.653986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train_Accuracy Score  Train_Precision Score  \\\n",
       "RandomForestClassifier                  1.000000               1.000000   \n",
       "BaggingClassifier                       0.999649               0.999699   \n",
       "GaussianNB                              0.612439               0.990368   \n",
       "XGBClassifier                           0.999147               0.999397   \n",
       "DecisionTreeClassifier                  1.000000               1.000000   \n",
       "KNeighborsClassifier                    0.974802               0.952800   \n",
       "GradientBoostingClassifier              0.921946               0.898464   \n",
       "AdaBoostClassifier                      0.888565               0.873709   \n",
       "LogisticRegression                      0.780544               0.833194   \n",
       "BernoulliNB                             0.615099               0.697163   \n",
       "\n",
       "                            Train_F1Score  Train_Recall  Test_Accuracy Score  \\\n",
       "RandomForestClassifier           1.000000      1.000000             0.972566   \n",
       "BaggingClassifier                0.999649      0.999649             0.971793   \n",
       "GaussianNB                       0.369457      0.612439             0.970634   \n",
       "XGBClassifier                    0.999146      0.999147             0.962519   \n",
       "DecisionTreeClassifier           1.000000      1.000000             0.947836   \n",
       "KNeighborsClassifier             0.975399      0.974802             0.926584   \n",
       "GradientBoostingClassifier       0.924180      0.921946             0.881762   \n",
       "AdaBoostClassifier               0.890737      0.888565             0.868238   \n",
       "LogisticRegression               0.761718      0.780544             0.853168   \n",
       "BernoulliNB                      0.513945      0.615099             0.809119   \n",
       "\n",
       "                            Test_Precision Score  Test_F1Score  Test_Recall  \\\n",
       "RandomForestClassifier                  0.686047      0.624339     0.972566   \n",
       "BaggingClassifier                       0.653061      0.636816     0.971793   \n",
       "GaussianNB                              0.864865      0.457143     0.970634   \n",
       "XGBClassifier                           0.528846      0.531401     0.962519   \n",
       "DecisionTreeClassifier                  0.388889      0.453441     0.947836   \n",
       "KNeighborsClassifier                    0.308370      0.424242     0.926584   \n",
       "GradientBoostingClassifier              0.221918      0.346154     0.881762   \n",
       "AdaBoostClassifier                      0.199495      0.316633     0.868238   \n",
       "LogisticRegression                      0.171021      0.274809     0.853168   \n",
       "BernoulliNB                             0.101833      0.168350     0.809119   \n",
       "\n",
       "                            Test_AUC_Score  \n",
       "RandomForestClassifier            0.780975  \n",
       "BaggingClassifier                 0.803839  \n",
       "GaussianNB                        0.654334  \n",
       "XGBClassifier                     0.757131  \n",
       "DecisionTreeClassifier            0.754138  \n",
       "KNeighborsClassifier              0.808216  \n",
       "GradientBoostingClassifier        0.836061  \n",
       "AdaBoostClassifier                0.819712  \n",
       "LogisticRegression                0.779293  \n",
       "BernoulliNB                       0.653986  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classalgo_test(X_train_smo,X_test,y_train_smo,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2de3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
